{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementazione del \"Treasure Maze\" in Python\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "In questa lezione, implementeremo una soluzione al problema del **\"Treasure Maze\"** utilizzando Python. Il \"Treasure Maze\" è un labirinto bidimensionale in cui un agente deve trovare il percorso ottimale dalla posizione iniziale alla posizione del tesoro, evitando ostacoli.\n",
    "\n",
    "Utilizzeremo le seguenti librerie:\n",
    "\n",
    "- **AIMA-Python**: per implementare gli algoritmi di ricerca.\n",
    "- **NumPy**: per la gestione delle matrici che rappresentano il labirinto.\n",
    "- **Matplotlib**: per visualizzare il percorso trovato all'interno del labirinto.\n",
    "\n",
    "## Obiettivi della lezione\n",
    "\n",
    "- Definire formalmente il dominio e i vincoli del problema.\n",
    "- Implementare la classe `TreasureMaze` derivata da `Problem` di AIMA-Python.\n",
    "- Risolvere il problema utilizzando algoritmi di ricerca informata (A*) e non informata (Breadth-First Search).\n",
    "- Visualizzare il percorso trovato mediante una rappresentazione grafica.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisiti\n",
    "\n",
    "Assicurarsi di avere installato le seguenti librerie:\n",
    "\n",
    "```bash\n",
    "pip install aima-python numpy matplotlib\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Descrizione formale del dominio e dei vincoli\n",
    "\n",
    "Prima di procedere con l'implementazione, definiamo formalmente il dominio e i vincoli:\n",
    "\n",
    "- **V1**: L'agente può compiere un solo passo alla volta.\n",
    "- **V2**: L'agente si può muovere solo fra stanze adiacenti (su, giù, sinistra, destra) e non può attraversare muri o ostacoli.\n",
    "- **V3**: L'agente deve raggiungere una posizione obiettivo specifica nel labirinto.\n",
    "- **V4**: Il labirinto è rappresentato come una griglia bidimensionale.\n",
    "- **Assunzioni**:\n",
    "  - Le posizioni nel labirinto sono definite da coordinate `(x, y)`.\n",
    "  - Le celle possono essere libere (`0`) o contenere ostacoli (`1`).\n",
    "  - La posizione iniziale e la posizione del tesoro sono note.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Implementazione delle classi per la ricerca nello spazio degli stati\n",
    "\n",
    "### Importazione delle librerie\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from aima.search import Problem, astar_search, breadth_first_tree_search\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "### Definizione della classe `TreasureMaze`\n",
    "\n",
    "Creiamo una classe `TreasureMaze` che deriva dalla classe `Problem` fornita da AIMA-Python.\n",
    "\n",
    "```python\n",
    "class TreasureMaze(Problem):\n",
    "    def __init__(self, initial, goal, maze):\n",
    "        \"\"\"\n",
    "        initial: Tupla (x, y) che rappresenta la posizione iniziale dell'agente.\n",
    "        goal: Tupla (x, y) che rappresenta la posizione obiettivo.\n",
    "        maze: Array bidimensionale numpy che rappresenta il labirinto.\n",
    "        \"\"\"\n",
    "        super().__init__(initial, goal)\n",
    "        self.maze = maze\n",
    "        self.rows = maze.shape[0]\n",
    "        self.cols = maze.shape[1]\n",
    "            \n",
    "    def actions(self, state):\n",
    "        \"\"\"Restituisce la lista delle azioni possibili nello stato dato.\"\"\"\n",
    "        actions = []\n",
    "        x, y = state\n",
    "        # Definizione delle possibili direzioni di movimento\n",
    "        directions = {'Up': (-1, 0), 'Down': (1, 0), 'Left': (0, -1), 'Right': (0, 1)}\n",
    "        for action, (dx, dy) in directions.items():\n",
    "            new_x, new_y = x + dx, y + dy\n",
    "            # Verifica che la nuova posizione sia all'interno dei limiti della griglia\n",
    "            if 0 <= new_x < self.rows and 0 <= new_y < self.cols:\n",
    "                # Verifica che la nuova posizione non sia un ostacolo\n",
    "                if self.maze[new_x][new_y] != 1:\n",
    "                    actions.append(action)\n",
    "        return actions\n",
    "            \n",
    "    def result(self, state, action):\n",
    "        \"\"\"Restituisce lo stato risultante dall'esecuzione di una data azione nello stato dato.\"\"\"\n",
    "        x, y = state\n",
    "        if action == 'Up':\n",
    "            return (x - 1, y)\n",
    "        elif action == 'Down':\n",
    "            return (x + 1, y)\n",
    "        elif action == 'Left':\n",
    "            return (x, y - 1)\n",
    "        elif action == 'Right':\n",
    "            return (x, y + 1)\n",
    "        else:\n",
    "            return state  # Azione non valida\n",
    "           \n",
    "    def goal_test(self, state):\n",
    "        \"\"\"Verifica se lo stato corrente è lo stato obiettivo.\"\"\"\n",
    "        return state == self.goal\n",
    "        \n",
    "    def h(self, node):\n",
    "        \"\"\"Funzione euristica per A* (distanza di Manhattan).\"\"\"\n",
    "        x1, y1 = node.state\n",
    "        x2, y2 = self.goal\n",
    "        return abs(x1 - x2) + abs(y1 - y2)\n",
    "```\n",
    "\n",
    "#### Spiegazione dei metodi\n",
    "\n",
    "- **`__init__`**: Inizializza il problema con lo stato iniziale, lo stato obiettivo e il labirinto.\n",
    "- **`actions`**: Restituisce le azioni possibili da uno stato, verificando che le mosse siano valide.\n",
    "- **`result`**: Determina lo stato successivo dato uno stato e un'azione.\n",
    "- **`goal_test`**: Verifica se lo stato corrente è lo stato obiettivo.\n",
    "- **`h`**: Funzione euristica per A*, utilizza la distanza di Manhattan.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Acquisizione e classificazione degli input\n",
    "\n",
    "Per questa implementazione, simuleremo l'acquisizione del labirinto e delle posizioni dell'agente.\n",
    "\n",
    "### Simulazione del labirinto\n",
    "\n",
    "Creiamo una matrice numpy per rappresentare il labirinto. Nella matrice:\n",
    "\n",
    "- `0` indica una cella libera.\n",
    "- `1` indica un ostacolo.\n",
    "\n",
    "```python\n",
    "# Labirinto simulato\n",
    "maze = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0]\n",
    "])\n",
    "```\n",
    "\n",
    "### Definizione dello stato iniziale e dello stato obiettivo\n",
    "\n",
    "```python\n",
    "# Posizione iniziale dell'agente\n",
    "initial_state = (0, 0)\n",
    "\n",
    "# Posizione del tesoro (goal)\n",
    "goal_state = (4, 4)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Risoluzione del problema\n",
    "\n",
    "Creiamo un'istanza del problema e applichiamo gli algoritmi di ricerca.\n",
    "\n",
    "### Creazione dell'istanza del problema\n",
    "\n",
    "```python\n",
    "# Creazione dell'istanza del problema\n",
    "problem = TreasureMaze(initial_state, goal_state, maze)\n",
    "```\n",
    "\n",
    "### Risoluzione con A* Search\n",
    "\n",
    "```python\n",
    "# Risoluzione con A* Search\n",
    "solution_node = astar_search(problem)\n",
    "```\n",
    "\n",
    "### Verifica della soluzione trovata\n",
    "\n",
    "```python\n",
    "if solution_node:\n",
    "    actions = solution_node.solution()\n",
    "    print(\"Soluzione trovata con A* Search:\")\n",
    "    print(\"Azioni:\", actions)\n",
    "    print(\"Costo del percorso:\", solution_node.path_cost)\n",
    "else:\n",
    "    print(\"Nessuna soluzione trovata con A* Search.\")\n",
    "```\n",
    "\n",
    "### Risoluzione con Breadth-First Search\n",
    "\n",
    "```python\n",
    "# Risoluzione con Breadth-First Search\n",
    "solution_node_bfs = breadth_first_tree_search(problem)\n",
    "\n",
    "if solution_node_bfs:\n",
    "    actions_bfs = solution_node_bfs.solution()\n",
    "    print(\"\\nSoluzione trovata con Breadth-First Search:\")\n",
    "    print(\"Azioni:\", actions_bfs)\n",
    "    print(\"Costo del percorso:\", solution_node_bfs.path_cost)\n",
    "else:\n",
    "    print(\"Nessuna soluzione trovata con Breadth-First Search.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Esecuzione e visualizzazione del piano\n",
    "\n",
    "### Funzione per ricostruire il percorso\n",
    "\n",
    "Definiamo una funzione per ottenere il percorso a partire dalle azioni.\n",
    "\n",
    "```python\n",
    "def get_path(initial_state, actions, problem):\n",
    "    state = initial_state\n",
    "    path = [state]\n",
    "    for action in actions:\n",
    "        state = problem.result(state, action)\n",
    "        path.append(state)\n",
    "    return path\n",
    "```\n",
    "\n",
    "### Funzione per visualizzare il labirinto e il percorso\n",
    "\n",
    "```python\n",
    "def visualize_maze(maze, path):\n",
    "    maze_visual = maze.copy()\n",
    "    for position in path:\n",
    "        x, y = position\n",
    "        if maze_visual[x][y] != 0:\n",
    "            continue\n",
    "        maze_visual[x][y] = 2  # 2 rappresenta il percorso dell'agente\n",
    "\n",
    "    # Configurazione della figura\n",
    "    plt.figure(figsize=(5,5))\n",
    "    cmap = plt.cm.Set3\n",
    "    plt.imshow(maze_visual, cmap=cmap)\n",
    "    cbar = plt.colorbar(ticks=[0,1,2], label='Legenda', shrink=0.7)\n",
    "    cbar.ax.set_yticklabels(['Libero', 'Ostacolo', 'Percorso'])\n",
    "    plt.clim(-0.5, 2.5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "### Visualizzazione del percorso trovato con A*\n",
    "\n",
    "```python\n",
    "if solution_node:\n",
    "    actions = solution_node.solution()\n",
    "    path = get_path(initial_state, actions, problem)\n",
    "    visualize_maze(maze, path)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codice completo\n",
    "\n",
    "Riuniamo tutti i pezzi insieme per avere una visione d'insieme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soluzione trovata con A* Search:\n",
      "Azioni: ['Right', 'Right', 'Right', 'Right', 'Down', 'Down', 'Down', 'Down']\n",
      "Costo del percorso: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Soluzione trovata con Breadth-First Search:\n",
      "Azioni: ['Down', 'Down', 'Down', 'Right', 'Right', 'Down', 'Right', 'Right']\n",
      "Costo del percorso: 8\n"
     ]
    }
   ],
   "source": [
    "# Import delle librerie\n",
    "import numpy as np\n",
    "from aima.search import Problem, astar_search, breadth_first_tree_search\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definizione della classe TreasureMaze\n",
    "class TreasureMaze(Problem):\n",
    "    def __init__(self, initial, goal, maze):\n",
    "        super().__init__(initial, goal)\n",
    "        self.maze = maze\n",
    "        self.rows = maze.shape[0]\n",
    "        self.cols = maze.shape[1]\n",
    "            \n",
    "    def actions(self, state):\n",
    "        actions = []\n",
    "        x, y = state\n",
    "        directions = {'Up': (-1, 0), 'Down': (1, 0), 'Left': (0, -1), 'Right': (0, 1)}\n",
    "        for action, (dx, dy) in directions.items():\n",
    "            new_x, new_y = x + dx, y + dy\n",
    "            if 0 <= new_x < self.rows and 0 <= new_y < self.cols:\n",
    "                if self.maze[new_x][new_y] != 1:\n",
    "                    actions.append(action)\n",
    "        return actions\n",
    "            \n",
    "    def result(self, state, action):\n",
    "        x, y = state\n",
    "        if action == 'Up':\n",
    "            return (x - 1, y)\n",
    "        elif action == 'Down':\n",
    "            return (x + 1, y)\n",
    "        elif action == 'Left':\n",
    "            return (x, y - 1)\n",
    "        elif action == 'Right':\n",
    "            return (x, y + 1)\n",
    "        else:\n",
    "            return state\n",
    "           \n",
    "    def goal_test(self, state):\n",
    "        return state == self.goal\n",
    "        \n",
    "    def h(self, node):\n",
    "        x1, y1 = node.state\n",
    "        x2, y2 = self.goal\n",
    "        return abs(x1 - x2) + abs(y1 - y2)\n",
    "\n",
    "# Funzioni ausiliarie\n",
    "def get_path(initial_state, actions, problem):\n",
    "    state = initial_state\n",
    "    path = [state]\n",
    "    for action in actions:\n",
    "        state = problem.result(state, action)\n",
    "        path.append(state)\n",
    "    return path\n",
    "\n",
    "def visualize_maze(maze, path):\n",
    "    maze_visual = maze.copy()\n",
    "    for position in path:\n",
    "        x, y = position\n",
    "        if maze_visual[x][y] != 0:\n",
    "            continue\n",
    "        maze_visual[x][y] = 2\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    cmap = plt.cm.Set3\n",
    "    plt.imshow(maze_visual, cmap=cmap)\n",
    "    cbar = plt.colorbar(ticks=[0,1,2], label='Legenda', shrink=0.7)\n",
    "    cbar.ax.set_yticklabels(['Libero', 'Ostacolo', 'Percorso'])\n",
    "    plt.clim(-0.5, 2.5)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# Labirinto e stati\n",
    "maze = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 0]\n",
    "])\n",
    "\n",
    "initial_state = (0, 0)\n",
    "goal_state = (4, 4)\n",
    "\n",
    "# Creazione del problema\n",
    "problem = TreasureMaze(initial_state, goal_state, maze)\n",
    "\n",
    "# Risoluzione con A* Search\n",
    "solution_node = astar_search(problem)\n",
    "\n",
    "if solution_node:\n",
    "    actions = solution_node.solution()\n",
    "    print(\"Soluzione trovata con A* Search:\")\n",
    "    print(\"Azioni:\", actions)\n",
    "    print(\"Costo del percorso:\", solution_node.path_cost)\n",
    "    path = get_path(initial_state, actions, problem)\n",
    "    visualize_maze(maze, path)\n",
    "else:\n",
    "    print(\"Nessuna soluzione trovata con A* Search.\")\n",
    "\n",
    "# Risoluzione con Breadth-First Search\n",
    "solution_node_bfs = breadth_first_tree_search(problem)\n",
    "\n",
    "if solution_node_bfs:\n",
    "    actions_bfs = solution_node_bfs.solution()\n",
    "    print(\"\\nSoluzione trovata con Breadth-First Search:\")\n",
    "    print(\"Azioni:\", actions_bfs)\n",
    "    print(\"Costo del percorso:\", solution_node_bfs.path_cost)\n",
    "else:\n",
    "    print(\"Nessuna soluzione trovata con Breadth-First Search.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
